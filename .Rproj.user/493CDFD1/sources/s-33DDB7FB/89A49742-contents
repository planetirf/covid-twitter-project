---
title: "covid_eda"
author: "Irfan Ainuddin, Ashley Person, Chicago"
date: "4/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(wordcloud)
library(textdata)
library(scales)
```

```{r}
## import data and clean
## deal with scientific notation
options(scipen = 999)

df <- readRDS(file = "covid-tweets-2020-04-17.rds")

who <- readRDS(file = "who_tweets.Rds")
cdc <- readRDS(file = "cdc_tweets.Rds")
```


```{r}
remove_reg <- "&amp;|&lt;|&gt;"

## Preparing public twitter text for sentiment analysis 
tweet_words <- df %>% 
                  ## remove the words from remove_reg variable above
                  mutate(text = str_remove_all(text, remove_reg)) %>%
                  ## tokenize the words for sentiment analysis
                  unnest_tokens(word, text, token="tweets", strip_url = TRUE) %>%
                  ## filter out stop words using all libraries(SMART, onix, snowball)
                  filter(!word %in% stop_words$word,
                         !word %in% str_remove_all(stop_words$word, "'"))

## tweets broken into each word.
tweet_words

```

```{r}

## Preparing public twitter text for sentiment analysis 
cdc_tweet_words <- cdc %>% 
                  ## remove the words from remove_reg variable above
                  mutate(text = str_remove_all(text, remove_reg)) %>%
                  ## tokenize the words for sentiment analysis
                  unnest_tokens(word, text, token="tweets", strip_url = TRUE) %>%
                  ## filter out stop words using all libraries(SMART, onix, snowball)
                  filter(!word %in% stop_words$word,
                         !word %in% str_remove_all(stop_words$word, "'"))

## tweets broken into each word.
cdc_tweet_words

```


```{r}


## Preparing public twitter text for sentiment analysis 
who_tweet_words <- who %>% 
                  ## remove the words from remove_reg variable above
                  mutate(text = str_remove_all(text, remove_reg)) %>%
                  ## tokenize the words for sentiment analysis
                  unnest_tokens(word, text, token="tweets", strip_url = TRUE) %>%
                  ## filter out stop words using all libraries(SMART, onix, snowball)
                  filter(!word %in% stop_words$word,
                         !word %in% str_remove_all(stop_words$word, "'"))

## tweets broken into each word.
who_tweet_words

```


```{r}
## Add counts for each sentiment w/ pivot_wider()
tweet_count <- tweet_words_nrc %>% group_by(tweet_id, sentiment) %>% count() %>%   pivot_wider(names_from = sentiment, values_from= n)

## Add counts foreach sentiment w/ pivot_wider()
cdc_tweet_count <- cdc_tweet_words_nrc %>% group_by(tweet_id, sentiment) %>% count() %>% pivot_wider(names_from = sentiment, values_from= n)

## Add counts for each sentiment w/ pivot_wider()
who_tweet_count <- who_tweet_words_nrc %>% group_by(tweet_id, sentiment) %>% count() %>% pivot_wider(names_from = sentiment, values_from= n)

```


```{r}
## Sentiment Counts
all_sentiment_count <- colSums(tweet_count[,-1], na.rm = TRUE)

## CDC sentiment count
cdc_sentiment_count <- colSums(cdc_tweet_count[,-1], na.rm = TRUE)

# WHO sentiment count
who_sentiment_count <- colSums(who_tweet_count[,-1], na.rm = TRUE)





```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
